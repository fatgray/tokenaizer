Разбиение текста на отдельные токены. Оснавная цель обеспечить удобный способ для текстов связанных с языками программирования
делить текст на токены. Обычно деление проиходит за счет поиск символов разделителей все что между разделителями
является токеном. 

Основные термины:
  * токен - текст которые описывается правилом
  * тип токена - алгоритм которым обнаружен текст, тип empty для пустокого токена
  * ид токена - уникальный идентификатор правила
  
В этом алгоритме реализовать подход настройки за счет правил и реализованя варианты: 

* токен все что между разделителями
* токен точное совпадение с шаблоном правила
* токен коментарий все что ограничено  между началльным словом и конечным словом
* токен лиерал все что ограничено  между началльным словом и конечным словом с возможностью экранирования внутри слова ограничения

Правила компиляться и могут быть сохранены в json или в формате функции javascript.
Исходный текст можно читать из файла, строки, стандартного ридера джава. 



Пример использование:

Для компиляции правил и создания токенайзера необходимо сделать
```java
Tokenizer tokenizer = TokenizerFactory.create()  // создадим фабрику тоенайзеров
                .addKeyword(new String[] {"begin","end"}) // добавим токены шаблоны слов
                .addKeyword(new String[] {":=","::"})     // добавим еще токены шаблоны слов
                .addComment("/*","*/")                    // добавим  коментарий многострочный
                .addComment("//","\n")                    // добавим однострочный коментарий
                .addSpace(" ;\n")                         // сомволы разделители токенов
                .addLiteral("'","'")                      // добавить литерал
                .setSkipSpace(false)                      // не возвращать тексты разделителей в поток
                .setIgnoreCase(true)                      // не учитывать различия прописные/строчные символы
                .newTokenizer();                          // создть токенайзер
```
Для использования токенайзера используется токой код 
```java
        tokenizer.openFile("text.txt");               // откроем файл для чтения

        String token;                                 // переменная для хранения токена
        do {
            token = tokenizer.nextToken();            // получить следующий токен
            System.out.println(                       // выведем в стандартный выходной поток информацию о токене
               tokenizer.curTokenId()+":"+            // id токена
               tokenizer.curTokenType()+":" +         // тип токена
               token +                                // текст токена
               " line="+tokenizer.curLine()+          // строка начала токена в тексте
               " pos="+tokenizer.curPos());           // позиция начала токена в тексте
        } while (token!=null);                        // если токенов больше нет

        tokenizer.close();                            // закрыть файл для чтения
```
